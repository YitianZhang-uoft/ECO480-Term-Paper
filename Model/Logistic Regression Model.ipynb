{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf2ea6-8b8f-400c-be20-77ac7e1e9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import inspect\n",
    "import warnings\n",
    "import pygam\n",
    "\n",
    "from pandas import DataFrame\n",
    "from sklearn import ensemble, metrics, model_selection, preprocessing, tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, max_error, median_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.feature_selection import RFE\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3946eb09-6ce3-4fcf-8856-8ecc26af8b92",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b411854-9919-476e-ae08-560a12b7f2f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df_selected = pd.read_csv('Data_selection.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c4282-1946-41ab-969e-ea7618ec733c",
   "metadata": {},
   "source": [
    "##### 1.1 Initial Fitting on data set with preliminary feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181b2ff-d351-448c-9e74-8ab55b5afb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_selected\n",
    "\n",
    "# Randomly split the data set into training and testing and deal with the imbalanced dependent variable using SMOTE\n",
    "y = df['TARGET']\n",
    "X = df.drop('TARGET', axis=1)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size = 0.75, shuffle = True, random_state = 480)\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=480)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create a logistic regression classifier object\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Use Recursive Feature Elimination (RFE) for stepwise variable selection\n",
    "rfe = RFE(logreg)\n",
    "rfe.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Fit the model using the selected features\n",
    "selected_features = X_train_resampled.columns[rfe.support_]\n",
    "logit_model = sm.Logit(y_train_resampled, sm.add_constant(X_train_resampled[selected_features]))\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Iteratively check VIF and remove variables with high VIF values\n",
    "max_vif = np.inf\n",
    "\n",
    "while max_vif > 10:\n",
    "    # Calculate VIF for the selected independent variables\n",
    "    vif = pd.DataFrame()\n",
    "    vif['VIF Factor'] = [variance_inflation_factor(X_train_resampled[selected_features].values, i) for i in range(X_train_resampled[selected_features].shape[1])]\n",
    "    vif['features'] = selected_features\n",
    "\n",
    "    # Remove variables with high VIF values\n",
    "    high_vif_features = vif[vif['VIF Factor'] > 10]['features']\n",
    "    selected_features = selected_features.drop(high_vif_features)\n",
    "\n",
    "    # Refit the logistic regression model using the remaining independent variables\n",
    "    logreg.fit(X_train_resampled[selected_features], y_train_resampled)\n",
    "\n",
    "    # Update max_vif\n",
    "    max_vif = vif['VIF Factor'].max()\n",
    "    \n",
    "# Calculate and display the final VIF values for the remaining independent variables\n",
    "vif = pd.DataFrame()\n",
    "vif['VIF Factor'] = [variance_inflation_factor(X_train_resampled[selected_features].values, i) for i in range(X_train_resampled[selected_features].shape[1])]\n",
    "vif['features'] = selected_features\n",
    "print(vif)\n",
    "\n",
    "logit_model = sm.Logit(y_train_resampled, sm.add_constant(X_train_resampled[selected_features]))\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Iteratively remove variables with high p-values and refit the model\n",
    "max_pvalue = np.inf\n",
    "while max_pvalue >= 0.05:\n",
    "    # Remove variables with high p-values\n",
    "    high_pvalue_features = result.pvalues[result.pvalues >= 0.05].index\n",
    "    selected_features = selected_features.drop(high_pvalue_features)\n",
    "\n",
    "    # Refit the logistic regression model using the remaining independent variables\n",
    "    logit_model = sm.Logit(y_train_resampled, sm.add_constant(X_train_resampled[selected_features]))\n",
    "    result = logit_model.fit()\n",
    "\n",
    "    # Update max_pvalue\n",
    "    max_pvalue = result.pvalues.max()\n",
    "\n",
    "# Display the final regression results\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b214e-d10c-4106-8aed-39620011d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training and test sets\n",
    "y_pred_train = result.predict(sm.add_constant(X_train_resampled[selected_features]))\n",
    "y_pred_test = result.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "# Compute in-sample performance metrics\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_pred_train.round())\n",
    "precision_train = precision_score(y_train_resampled, y_pred_train.round())\n",
    "recall_train = recall_score(y_train_resampled, y_pred_train.round())\n",
    "f1_score_train = f1_score(y_train_resampled, y_pred_train.round())\n",
    "roc_auc_train = roc_auc_score(y_train_resampled, y_pred_train.round())\n",
    "\n",
    "# Compute out-of-sample performance metrics\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test.round())\n",
    "precision_test = precision_score(y_test, y_pred_test.round())\n",
    "recall_test = recall_score(y_test, y_pred_test.round())\n",
    "f1_score_test = f1_score(y_test, y_pred_test.round())\n",
    "roc_auc_test = roc_auc_score(y_train_resampled, y_pred_train.round())\n",
    "\n",
    "# assuming you have already computed the performance metrics\n",
    "data = {'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score', 'ROC AUC'],\n",
    "        'Training': [accuracy_train, precision_train, recall_train, f1_score_train, roc_auc_train],\n",
    "        'Test': [accuracy_test, precision_test, recall_test, f1_score_test, roc_auc_test]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e6cd7-ddd2-4ee5-80c5-3fa6f93e7c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = mean_squared_error(y_train_resampled, y_pred_train, squared = False)\n",
    "mae_train = mean_absolute_error(y_train_resampled, y_pred_train)\n",
    "\n",
    "rmse_test = mean_squared_error(y_test, y_pred_test, squared = False)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "data = {'Metric': ['RMSE', 'MAE'],\n",
    "        'Training': [rmse_train, mae_train],\n",
    "        'Test': [rmse_test, mae_test]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea53c44-07e3-4006-8d8d-1116f53ad4e2",
   "metadata": {},
   "source": [
    "##### 1.2 Hyperparameter Tuning using Cross-validation on data set with preliminary feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0026d0b-5646-4abb-9ad3-2d4abc0a37db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "              'max_iter': [100, 200, 300]}\n",
    "\n",
    "# Create a logistic regression classifier object\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Perform hyperparameter tuning using cross-validation\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5)\n",
    "grid_search.fit(X_train_resampled[selected_features], y_train_resampled)\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print('Best hyperparameters:', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e087ab-20ce-466f-bd21-0ad3ee125d49",
   "metadata": {},
   "source": [
    "##### 1.3 Refit the model using optimal parameters found through hyperparameter tuning on data set with preliminary feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fbf43-77d2-49ec-ba1c-4e32e5f60845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logistic regression classifier object with the best hyperparameters\n",
    "logreg = LogisticRegression(C=0.1, max_iter=300, penalty='l2', solver='sag')\n",
    "\n",
    "# Use Recursive Feature Elimination (RFE) for stepwise variable selection\n",
    "rfe = RFE(logreg)\n",
    "rfe.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Fit the model using the selected features\n",
    "selected_features = X_train_resampled.columns[rfe.support_]\n",
    "logit_model = sm.Logit(y_train_resampled, sm.add_constant(X_train_resampled[selected_features]))\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Iteratively check VIF and remove variables with high VIF values\n",
    "max_vif = np.inf\n",
    "\n",
    "while max_vif > 10:\n",
    "    # Calculate VIF for the selected independent variables\n",
    "    vif = pd.DataFrame()\n",
    "    vif['VIF Factor'] = [variance_inflation_factor(X_train_resampled[selected_features].values, i) for i in range(X_train_resampled[selected_features].shape[1])]\n",
    "    vif['features'] = selected_features\n",
    "\n",
    "    # Remove variables with high VIF values\n",
    "    high_vif_features = vif[vif['VIF Factor'] > 10]['features']\n",
    "    selected_features = selected_features.drop(high_vif_features)\n",
    "\n",
    "    # Refit the logistic regression model using the remaining independent variables\n",
    "    logreg.fit(X_train_resampled[selected_features], y_train_resampled)\n",
    "\n",
    "    # Update max_vif\n",
    "    max_vif = vif['VIF Factor'].max()\n",
    "    \n",
    "# Calculate and display the final VIF values for the remaining independent variables\n",
    "vif = pd.DataFrame()\n",
    "vif['VIF Factor'] = [variance_inflation_factor(X_train_resampled[selected_features].values, i) for i in range(X_train_resampled[selected_features].shape[1])]\n",
    "vif['features'] = selected_features\n",
    "print(vif)\n",
    "\n",
    "logit_model = sm.Logit(y_train_resampled, sm.add_constant(X_train_resampled[selected_features]))\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Iteratively remove variables with high p-values and refit the model\n",
    "max_pvalue = np.inf\n",
    "while max_pvalue >= 0.05:\n",
    "    # Remove variables with high p-values\n",
    "    high_pvalue_features = result.pvalues[result.pvalues >= 0.05].index\n",
    "    selected_features = selected_features.drop(high_pvalue_features)\n",
    "\n",
    "    # Refit the logistic regression model using the remaining independent variables\n",
    "    logit_model = sm.Logit(y_train_resampled, sm.add_constant(X_train_resampled[selected_features]))\n",
    "    result = logit_model.fit()\n",
    "\n",
    "    # Update max_pvalue\n",
    "    max_pvalue = result.pvalues.max()\n",
    "\n",
    "# Display the final regression results\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23055fe-f8b0-4e28-8d4b-20fdf060af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training and test sets\n",
    "y_pred_train = result.predict(sm.add_constant(X_train_resampled[selected_features]))\n",
    "y_pred_test = result.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "# Compute in-sample performance metrics\n",
    "accuracy_train = accuracy_score(y_train_resampled, y_pred_train.round())\n",
    "precision_train = precision_score(y_train_resampled, y_pred_train.round())\n",
    "recall_train = recall_score(y_train_resampled, y_pred_train.round())\n",
    "f1_score_train = f1_score(y_train_resampled, y_pred_train.round())\n",
    "roc_auc_train = roc_auc_score(y_train_resampled, y_pred_train.round())\n",
    "\n",
    "# Compute out-of-sample performance metrics\n",
    "accuracy_train = accuracy_score(y_test, y_pred_test.round())\n",
    "precision_train = precision_score(y_test, y_pred_test.round())\n",
    "recall_train = recall_score(y_test, y_pred_test.round())\n",
    "f1_score_train = f1_score(y_test, y_pred_test.round())\n",
    "roc_auc_train = roc_auc_score(y_train_resampled, y_pred_train.round())\n",
    "\n",
    "# assuming you have already computed the performance metrics\n",
    "data = {'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score', 'ROC AUC'],\n",
    "        'Training': [accuracy_train, precision_train, recall_train, f1_score_train, roc_auc_train],\n",
    "        'Test': [accuracy_test, precision_test, recall_test, f1_score_test, roc_auc_test]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166e00f-77db-4f53-a4b3-d6035511c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = mean_squared_error(y_train_resampled, y_pred_train, squared = False)\n",
    "mae_train = mean_absolute_error(y_train_resampled, y_pred_train)\n",
    "\n",
    "rmse_test = mean_squared_error(y_test, y_pred_test, squared = False)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "data = {'Metric': ['RMSE', 'MAE'],\n",
    "        'Training': [rmse_train, mae_train],\n",
    "        'Test': [rmse_test, mae_test]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d15c8a-b64a-433b-acbe-af3537ac3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "threshold = 0.5\n",
    "y_pred_test = np.where(y_pred_test > threshold, 1, 0)\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_pred_test)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "pyplot.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=pyplot.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['TARGET = 0', 'TARGET = 1']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "pyplot.xticks(tick_marks, class_names, rotation=25)\n",
    "pyplot.yticks(tick_marks2, class_names, rotation=0)\n",
    "pyplot.xlabel('Predicted label')\n",
    "pyplot.ylabel('True label')\n",
    "pyplot.title('Confusion Matrix for Random Forest Model')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32de5d3-980d-4e2e-80f3-eb257eb9a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_linearity(df, target, features):\n",
    "    \"\"\"\n",
    "    Check linearity between independent variables and the log odds assumption.\n",
    "    \n",
    "    :param df: DataFrame containing the data\n",
    "    :param target: Name of the target variable\n",
    "    :param features: List of feature names\n",
    "    :return: DataFrame containing the p-values for each feature\n",
    "    \"\"\"\n",
    "    y = df[target]\n",
    "    p_values = []\n",
    "    for feature in features:\n",
    "        x = df[feature]\n",
    "        x = sm.add_constant(x)\n",
    "        model = sm.Logit(y, x)\n",
    "        result = model.fit()\n",
    "        p_values.append(result.pvalues[1])\n",
    "    \n",
    "    results_df = pd.DataFrame({'Feature': features, 'p-value': p_values})\n",
    "    return results_df\n",
    "\n",
    "results_df = check_linearity(df_selected, 'TARGET', selected_features)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57cdc6-a5d9-43f1-be1f-9af385404a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Wald statistics for each variable\n",
    "wald_statistics = result.params / result.bse\n",
    "wald_statistics = wald_statistics ** 2\n",
    "\n",
    "# Get the top 10 variables with the highest Wald statistics\n",
    "top_10_variables = wald_statistics.nlargest(10)\n",
    "\n",
    "# Display the results\n",
    "top_10_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b7b3a-fab0-41fc-a82a-16fe04f26328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of top 10 features\n",
    "indices = np.argsort(top_10_variables)[::-1][:10]\n",
    "\n",
    "# Fit a logistic regression model using scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_resampled.iloc[:, indices], y_train_resampled)\n",
    "\n",
    "# Calculate partial dependence\n",
    "fig, ax = pyplot.subplots(5, 2, figsize=(20, 20))\n",
    "pdp_results = PartialDependenceDisplay.from_estimator(logreg, X_train_resampled.iloc[:, indices], range(10),\n",
    "                                                      feature_names=X_train_resampled.columns[indices],\n",
    "                                                      ax=ax.ravel())\n",
    "pyplot.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
