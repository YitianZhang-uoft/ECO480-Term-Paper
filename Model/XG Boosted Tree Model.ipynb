{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf2ea6-8b8f-400c-be20-77ac7e1e9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import inspect\n",
    "import warnings\n",
    "\n",
    "from sklearn import ensemble, metrics, model_selection, preprocessing, tree\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, max_error, median_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3946eb09-6ce3-4fcf-8856-8ecc26af8b92",
   "metadata": {},
   "source": [
    "## XG Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b411854-9919-476e-ae08-560a12b7f2f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df_selected = pd.read_csv('Data_selection.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c4282-1946-41ab-969e-ea7618ec733c",
   "metadata": {},
   "source": [
    "##### 1.1 Initial Fitting on data set with preliminary feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181b2ff-d351-448c-9e74-8ab55b5afb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_selected\n",
    "\n",
    "# Randomly split the data set into training and testing and deal with the imbalanced dependent variable using SMOTE\n",
    "y = df['TARGET']\n",
    "X = df.drop('TARGET', axis=1)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size = 0.75, shuffle = True, random_state = 480)\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=480)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train_resampled.columns = [col.replace('[', '').replace(']', '').replace('<', '') for col in X_train_resampled.columns]\n",
    "X_test.columns = [col.replace('[', '').replace(']', '').replace('<', '') for col in X_test.columns]\n",
    "\n",
    "# Fit an XGBoost model with 25 trees to the training data\n",
    "XGBModel = XGBClassifier(n_estimators=25, random_state=480)\n",
    "XGBModel.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# make predictions on the training and test sets\n",
    "y_pred_train = XGBModel.predict(X_train_resampled)\n",
    "y_pred_test = XGBModel.predict(X_test)\n",
    "\n",
    "# compute in-sample performance metrics\n",
    "accuracy_train = metrics.accuracy_score(y_train_resampled, y_pred_train)\n",
    "precision_train = metrics.precision_score(y_train_resampled, y_pred_train)\n",
    "recall_train = metrics.recall_score(y_train_resampled, y_pred_train)\n",
    "f1_score_train = metrics.f1_score(y_train_resampled, y_pred_train)\n",
    "roc_auc_train = metrics.roc_auc_score(y_train_resampled, y_pred_train)\n",
    "\n",
    "# compute out-of-sample performance metrics\n",
    "accuracy_test = metrics.accuracy_score(y_test, y_pred_test)\n",
    "precision_test = metrics.precision_score(y_test, y_pred_test)\n",
    "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
    "f1_score_test = metrics.f1_score(y_test, y_pred_test)\n",
    "roc_auc_test = metrics.roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "# assuming you have already computed the performance metrics\n",
    "data = {'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score', 'ROC AUC'],\n",
    "        'Training': [accuracy_train, precision_train, recall_train, f1_score_train, roc_auc_train],\n",
    "        'Test': [accuracy_test, precision_test, recall_test, f1_score_test, roc_auc_test]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e6cd7-ddd2-4ee5-80c5-3fa6f93e7c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = mean_squared_error(y_train_resampled, y_pred_train, squared = False)\n",
    "mae_train = mean_absolute_error(y_train_resampled, y_pred_train)\n",
    "\n",
    "rmse_test = mean_squared_error(y_test, y_pred_test, squared = False)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "data = {'Metric': ['RMSE', 'MAE'],\n",
    "        'Training': [rmse_train, mae_train],\n",
    "        'Test': [rmse_test, mae_test]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea53c44-07e3-4006-8d8d-1116f53ad4e2",
   "metadata": {},
   "source": [
    "##### 1.2 Hyperparameter Tuning using Cross-validation on data set with preliminary feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0026d0b-5646-4abb-9ad3-2d4abc0a37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.8, 1],\n",
    "    'colsample_bytree': [0.5, 0.8, 1]\n",
    "}\n",
    "\n",
    "# create an XGBoost model\n",
    "xgb = XGBClassifier(random_state=480, max_depth = 3, learning_rate = 0.1, n_estimators = 300, gamma = 0, min_child_weight = 1, subsample = 1, colsample_bytree = 1)\n",
    "\n",
    "# create a grid search object\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5)\n",
    "\n",
    "# fit the grid search object to the data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e087ab-20ce-466f-bd21-0ad3ee125d49",
   "metadata": {},
   "source": [
    "##### 1.3 Refit the model using optimal parameters found through hyperparameter tuning on data set with preliminary feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fbf43-77d2-49ec-ba1c-4e32e5f60845",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = XGBClassifier(random_state=480, max_depth = 3, learning_rate = 0.1, n_estimators = 300, gamma = 0, min_child_weight = 1, subsample = 1, colsample_bytree = 1)\n",
    "\n",
    "# fit the model to the training data\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# make predictions on the training and test sets\n",
    "y_pred_train = rf.predict(X_train_resampled)\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "# compute in-sample performance metrics\n",
    "accuracy_train = metrics.accuracy_score(y_train_resampled, y_pred_train)\n",
    "precision_train = metrics.precision_score(y_train_resampled, y_pred_train)\n",
    "recall_train = metrics.recall_score(y_train_resampled, y_pred_train)\n",
    "f1_score_train = metrics.f1_score(y_train_resampled, y_pred_train)\n",
    "roc_auc_train = metrics.roc_auc_score(y_train_resampled, y_pred_train)\n",
    "\n",
    "# compute out-of-sample performance metrics\n",
    "accuracy_test = metrics.accuracy_score(y_test, y_pred_test)\n",
    "precision_test = metrics.precision_score(y_test, y_pred_test)\n",
    "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
    "f1_score_test = metrics.f1_score(y_test, y_pred_test)\n",
    "roc_auc_test = metrics.roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "# assuming you have already computed the performance metrics\n",
    "data = {'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score', 'ROC AUC'],\n",
    "        'Training': [accuracy_train, precision_train, recall_train, f1_score_train, roc_auc_train],\n",
    "        'Test': [accuracy_test, precision_test, recall_test, f1_score_test, roc_auc_test]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23055fe-f8b0-4e28-8d4b-20fdf060af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = mean_squared_error(y_train_resampled, y_pred_train, squared = False)\n",
    "mae_train = mean_absolute_error(y_train_resampled, y_pred_train)\n",
    "\n",
    "rmse_test = mean_squared_error(y_test, y_pred_test, squared = False)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "data = {'Metric': ['RMSE', 'MAE'],\n",
    "        'Training': [rmse_train, mae_train],\n",
    "        'Test': [rmse_test, mae_test]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d15c8a-b64a-433b-acbe-af3537ac3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_test, y_pred_test)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "pyplot.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=pyplot.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['TARGET = 0', 'TARGET = 1']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "pyplot.xticks(tick_marks, class_names, rotation=25)\n",
    "pyplot.yticks(tick_marks2, class_names, rotation=0)\n",
    "pyplot.xlabel('Predicted label')\n",
    "pyplot.ylabel('True label')\n",
    "pyplot.title('Confusion Matrix for Random Forest Model')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20451134-7ec0-4cbf-8ce6-e873147f0d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "importance_df = pd.DataFrame({'Feature': X_train_resampled.columns, 'Importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance and select the top 10 features\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
    "\n",
    "# Display the results\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541222f1-27ac-4f91-b60b-d28de2493c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# get indices of top 10 features\n",
    "indices = np.argsort(importances)[::-1][:10]\n",
    "\n",
    "# calculate partial dependence\n",
    "fig, ax = pyplot.subplots(5, 2, figsize=(20, 20))\n",
    "pdp_results = PartialDependenceDisplay.from_estimator(rf, X_train_resampled, indices,\n",
    "                                                      feature_names=X_train_resampled.columns,\n",
    "                                                      ax=ax.ravel())\n",
    "# reduce the font size of the titles\n",
    "for ax in pdp_results.axes_.ravel():\n",
    "    ax.set_title(ax.get_title(), fontsize=5)\n",
    "    \n",
    "pyplot.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
